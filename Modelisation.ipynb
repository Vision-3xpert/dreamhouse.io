{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import folium as fl\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut, GeocoderUnavailable, GeocoderQuotaExceeded\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import re\n",
    "quartier_url = 'https://data.montreal.ca/dataset/00bd85eb-23aa-4669-8f1b-ba9a000e3dd8/resource/e9b0f927-8f75-458c-8fda-b5da65cc8b73/download/limadmin.geojson'\n",
    "Montreal = []\n",
    "\n",
    "try:\n",
    "    r2 = requests.get(quartier_url, timeout=30)\n",
    "\n",
    "except requests.exceptions.RequestException as erreur2:\n",
    "    print(f\"Erreur de connexion à l'adresse web suivante {quartier_url} : {erreur2}\")\n",
    "\n",
    "else:\n",
    "    if r2.status_code >= 200 and r2.status_code <= 299:\n",
    "        Montreal = r2.json()\n",
    "    else:\n",
    "        print(f\"Erreur de connexion à l'adresse web suivante {quartier_url} : erreur {r2.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ameneties\n",
    "# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#italian restaurants\n",
    "italien = pd.read_csv('CSVs/Restaurant-Italien.csv')\n",
    "new_italien = pd.read_csv('CSVs/new-towns-italien.csv')\n",
    "#TODO  Rajouter le type de restaurant correspondant\n",
    "italien[[\"Type\"]] = \"italien\"\n",
    "new_italien[[\"Type\"]] = \"italien\"\n",
    "Italy = pd.concat([italien,new_italien])\n",
    "Italy = Italy.drop_duplicates()\n",
    "\n",
    "#greek restaurants\n",
    "Grec = pd.read_csv('CSVs/Restaurant-Grec.csv')\n",
    "new_greek = pd.read_csv('CSVs/new-towns-greek.csv')\n",
    "Grec[[\"Type\"]] =  \"grec\"\n",
    "new_greek[[\"Type\"]] = \"grec\"\n",
    "Greek = pd.concat([Grec,new_greek])\n",
    "Greek = Greek.drop_duplicates()\n",
    "\n",
    "\n",
    "#African Restaurants\n",
    "Africain = pd.read_csv('CSVs/Restaurant Africain.csv')\n",
    "Africain[[\"Type\"]] = \"africain\"\n",
    "\n",
    "\n",
    "#Antillais Restaurants\n",
    "Antillais = pd.read_csv('CSVs/Restaurant-Antillais.csv')\n",
    "Antillais[[\"Type\"]] =  \"antillais\"\n",
    "\n",
    "#Asian Restaurants\n",
    "Asiatique = pd.read_csv('CSVs/Restaurant-Asiatique.csv')\n",
    "new_asian = pd.read_csv(\"CSVs/new-towns-asian.csv\")\n",
    "Asiatique[[\"Type\"]] =  \"asiatique\"\n",
    "new_asian[[\"Type\"]] = \"asiatique\"\n",
    "Asian = pd.concat([Asiatique,new_asian])\n",
    "Asian = Asian.drop_duplicates()\n",
    "\n",
    "#Mexican Restaurants\n",
    "Mexicain = pd.read_csv('CSVs/Restaurant-Mexicain.csv')\n",
    "Mexicain[[\"Type\"]] = \"mexicain\"\n",
    "\n",
    "#Healthy Restaurants\n",
    "Santé = pd.read_csv('CSVs/Restaurant-Santé.csv')\n",
    "new_healthy = pd.read_csv(\"CSVs/new-towns-healthy.csv\")\n",
    "Santé[[\"Type\"]] = \"santé\"\n",
    "new_healthy[[\"Type\"]] = \"santé\"\n",
    "Healthy = pd.concat([Santé,new_healthy])\n",
    "Healthy = Healthy.drop_duplicates()\n",
    "\n",
    "#Coffee place\n",
    "Café = pd.read_csv('CSVs/Café.csv')\n",
    "new_coffee = pd.read_csv(\"CSVs/new-towns-coffee.csv\")\n",
    "Café[[\"Type\"]] = \"café\"\n",
    "new_coffee[[\"Type\"]] = \"café\"\n",
    "Coffee = pd.concat([Café,new_coffee])\n",
    "Coffee = Coffee.drop_duplicates()\n",
    "#All Restaurants\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#Neighbourhoods Data ( GPS coordinates + Area and Population)\n",
    "neighborhoods = gpd.read_file(\"MTLTieks.geojson\")\n",
    "superficie = pd.read_csv('CSVs/Superficie_quartier.csv')\n",
    "# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#Properties\n",
    "Propriétés = pd.read_excel('CSVs/Centris_scraping2.xlsx')\n",
    "## Clean the address list from Initial Property list\n",
    "Addresse_list = Propriétés['Addresse'].tolist()\n",
    "for i in range(len(Addresse_list)):\n",
    "   ##TODO Retirer toute l'information qui vient après \", Montréal\" (mettons (123 avenue xyz, Montréal, XYZ) --> (123, avenue xyz, Montréal))\n",
    "   Addresse_list[i] = (Addresse_list[i].split(', Montréal')[0]+\", Montréal\") \n",
    "\n",
    "   ## Retirer toutes les lettres qui suiveront des numéro civique (Exemple 123A de la gauchetière --> 123 de la gauchetière)\n",
    "   Addresse_list[i] = re.sub(r'\\d+[A-Za-z]*', lambda x: x.group().rstrip('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdfghijklmnopqrstuvwxyz'), Addresse_list[i])   # address = Addresse_list[i]\n",
    "\n",
    "   ## Ajouter un \"e\" lorsque nous avons des cas comme '20 rue --> 20e rue OU 8 avenue --> 8e avenue\n",
    "   Addresse_list[i] = re.sub(r'^(\\d+), (\\d+) Avenue', r'\\1, \\2e Avenue', Addresse_list[i])\n",
    "   Addresse_list[i] = re.sub(r'^(\\d+), (\\d+) Rue', r'\\1, \\2e Rue', Addresse_list[i])\n",
    "\n",
    "   #TODO Nettoyer pour les appartements, les retirer exemple (123, app. 808, avneue xyz --> 123, avenue xyz)\n",
    "   Addresse_list[i] = re.sub(r'app\\..*?, ', '', Addresse_list[i])\n",
    "\n",
    "   #TODO Retirer les Abbrévations de Pointes-aux-trembles et RDP des addresses\n",
    "   Addresse_list[i] =Addresse_list[i].replace(\" (R.-d.-P.)\",\"\")\n",
    "   Addresse_list[i]=Addresse_list[i].replace(\" (P.-a.-T.)\",\"\")\n",
    "\n",
    "   #TODO Retirer les \"quartier...\" Exemple( 123, avenue xyz, Dorval, Quartier Sud --> 123, avenue xyz, Dorval)\n",
    "   Addresse_list[i] = re.sub(\", Quartier .*, \", \", \",Addresse_list[i])\n",
    "\n",
    "   #TODO Retirer les addresses double (123-125 avenue xyz --> 123, avenue xyz)\n",
    "   Addresse_list[i] = re.sub(r' - \\d+', '', Addresse_list[i])\n",
    "\n",
    "   #TODO Nettoyer pour les appartements, les retirer exemple (123, app. 808, avneue xyz --> 123, avenue xyz)\n",
    "   Addresse_list[i] = (re.sub(r'app\\.\\s*([A-Za-z\\d]+, )', '', Addresse_list[i]))\n",
    "   match = re.search(r\"app\\.\", Addresse_list[i])\n",
    "   if match:\n",
    "      Addresse_list[i] = re.sub(r\"app\\.\\s\\d+, \", \"\", Addresse_list[i])\n",
    "\n",
    "   #TODO enlever les d'\n",
    "   Addresse_list[i] = Addresse_list[i].replace(\" d'\",\" \")\n",
    "Propriétés['Addresse'] = Addresse_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the function to extract different interest place around\n",
    "def get_place_data(url,df):\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(f\"{url}{1}\")\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    container = soup.find_all(\"div\", {\"class\":\"col-auto\"})\n",
    "    for i in container:\n",
    "        if i.find(\"h2\") is not None:\n",
    "            result = i.find(\"h2\")\n",
    "    #result= [i.find(\"h2\") for i in container if i.find(\"h2\") is not None]\n",
    "    stringresult = (result.text).split(\"sur \")\n",
    "    intresult = int((stringresult[1]).split(\" \")[0])\n",
    "    iterations = ((intresult//100)+2)\n",
    "    quartier = []\n",
    "    centers = []\n",
    "    location = []\n",
    "    for i in range(1,iterations):\n",
    "        time.sleep(5)\n",
    "        driver.get(f\"{url}{i}\")\n",
    "        # Récupérez le contenu HTML de la page\n",
    "        html = driver.page_source\n",
    "        # Utilisez BeautifulSoup pour parser le contenu HTML\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        all_centers = (soup.find_all(\"div\", {\"class\": \"list-group-item-title\"}))\n",
    "        centers.extend([center.text for center in all_centers])\n",
    "        address_content = (soup.find_all(\"div\", {\"class\": \"list-group-item-content\"}))\n",
    "        for address in address_content:\n",
    "            if len(address) == 1:\n",
    "                city = address.find_next(\"div\")\n",
    "            elif len(address) == 2:\n",
    "                loc = address.find_next(\"div\")\n",
    "                city = loc.find_next(\"div\")\n",
    "            elif len(address) == 3:\n",
    "                badge = address.find_next(\"div\")\n",
    "                loc = badge.find_next(\"div\")\n",
    "                city = loc.find_next(\"div\")\n",
    "            quartier.append(city.text)\n",
    "            location.append(loc.text)\n",
    "    df = pd.DataFrame({\"Centre\": centers, \"Addresse\": location, \"Quartier\": quartier})\n",
    "    return df\n",
    "\n",
    "##TODO Transforme l'adresse en Point géographique (Lat,Lon,Alt) 123 avenue xyz, montréal --> (-73,45,0)\n",
    "def get_location(df):\n",
    "    locator = Nominatim(user_agent=\"myGeocoder\", timeout=10)\n",
    "    df['location'] = df['Addresse'].apply(locator.geocode)\n",
    "    df['point'] = df['location'].apply(lambda loc: tuple(loc.point) if loc else None)\n",
    "\n",
    "\n",
    "    return df\n",
    "#TODO Découper le point géogrpahique en 3 colonnes séparés\n",
    "def get_lat_lon(df):\n",
    "    df[['Lat', 'Lon', 'Alt']] = df['point'].apply(pd.Series)\n",
    "    df['Lat'] = df['Lat'].astype(float)\n",
    "    df['Lon'] = df['Lon'].astype(float)\n",
    "    df = df.drop(columns=['point', 'Alt'])\n",
    "    return df\n",
    "\n",
    "#TODO Aller chercher les limites geJSOM d'un quartier et trouver dans quel qaurtier appartient \"x\" point géogrpahique Lon,Lat Exemple -73.5,45.22 --> Verdun\n",
    "def Link_map_data(df):\n",
    "    df[\"geometry\"] = gpd.points_from_xy(df[\"Lon\"], df[\"Lat\"])\n",
    "    df = gpd.GeoDataFrame(df, geometry=\"geometry\")\n",
    "    df1 = gpd.sjoin(df, neighborhoods, how=\"left\", op='within')\n",
    "# Ajoutez une colonne de quartier à votre dataframe de df\n",
    "    df[\"NOM\"] = df1[\"NOM\"]\n",
    "    if 'location' in df.columns:\n",
    "        df =df.drop(columns=['location'])\n",
    "    if 'geometry' in df.columns:\n",
    "        df = df.drop(columns=['geometry'])\n",
    "\n",
    "    return df\n",
    "\n",
    "def apply_data_map(dforiginal,dfgrouped,dffinal):\n",
    "    dffinal = pd.merge(dforiginal,dfgrouped, on =\"NOM\", how=\"inner\")\n",
    "    return\n",
    "\n",
    "#Prop_map = get_location(Propriétés)\n",
    "#Prop_map = get_lat_lon(Prop_map)\n",
    "#Prop_map = Link_map_data(Prop_map)\n",
    "#Prop_map.to_csv(\"Export/Houses2V1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Call the function on interest places\n",
    "#Sportscenters = pd.DataFrame\n",
    "#sportsurl = \"https://montreal.ca/lieux?filter=true&mtl_content.lieux.category.code=CENT&page=\"\n",
    "#Sportscenters = get_place_data(sportsurl,Sportscenters)\n",
    "#Sportscenters[\"Addresse\"] = Sportscenters[\"Addresse\"].apply(lambda x: x + \", Montréal\")\n",
    "#Sportscenters = get_location(Sportscenters)\n",
    "#Sportscenters=get_lat_lon(Sportscenters)\n",
    "#Sportscenters = Link_map_data(Sportscenters)\n",
    "\n",
    "\n",
    "\n",
    "#Communitycenters = pd.DataFrame\n",
    "#communityurl = \"https://montreal.ca/lieux?mtl_content.lieux.category.code=BIBL&page=\"\n",
    "#Communitycenters = get_place_data(communityurl,Communitycenters)\n",
    "#Communitycenters[\"Addresse\"] = Communitycenters[\"Addresse\"].apply(lambda x: x + \", Montréal\")\n",
    "#Communitycenters = get_location(Communitycenters)\n",
    "#Communitycenters=get_lat_lon(Communitycenters)\n",
    "#Communitycenters = Link_map_data(Communitycenters)\n",
    "\n",
    "\n",
    "#Parcs = pd.DataFrame\n",
    "#parcsurl = \"https://montreal.ca/lieux?filter=true&mtl_content.lieux.category.code=PARC&page=\"\n",
    "#Parcs = get_place_data(parcsurl,Parcs)\n",
    "#Parcs[\"Addresse\"] = Parcs[\"Addresse\"].apply(lambda x: x + \", Montréal\")\n",
    "#Parcs = get_location(Parcs)\n",
    "#Parcs=get_lat_lon(Parcs)\n",
    "#Parcs = Link_map_data(Parcs)\n",
    "\n",
    "\n",
    "\n",
    "#Mairies = pd.DataFrame()\n",
    "#mairiesurl = \"https://montreal.ca/lieux?mtl_content.lieux.installation.code=MAIR&PAGE=\"\n",
    "#Mairies = get_place_data(mairiesurl,Mairies)\n",
    "#Mairies = Mairies[Mairies['Centre'].str.contains(\"Mairie d'arrondissement\")].reset_index().drop(columns=[\"index\"])\n",
    "#Mairies['Addresse'].replace([\"5160, boul. Décarie, bureau 600\",\"201 de l'avenue Laurier Est\"], [\"5160, boul. Décarie, Montreal\", \"201, avenue Laurier Est, Montreal\"], inplace=True)\n",
    "#Mairies = get_location(Mairies)\n",
    "#Mairies = get_lat_lon(Mairies)\n",
    "#Mairies = Link_map_data(Mairies)\n",
    "\n",
    "#Marker_mairies = {(row['Lat'],row['Lon']): row['Centre'] for i, row in Mairies.iterrows()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parcs.to_csv(\"Export/Parcs.csv\")\n",
    "#Communitycenters.to_csv(\"Export/Communitycenters.csv\")\n",
    "#Sportscenters.to_csv(\"Export/Sportscenters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thier\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3398: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\thier\\AppData\\Local\\Temp\\ipykernel_12316\\2905187142.py:64: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: None\n",
      "Right CRS: EPSG:4326\n",
      "\n",
      "  df1 = gpd.sjoin(df, neighborhoods, how=\"left\", op='within')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nom</th>\n",
       "      <th>Rue</th>\n",
       "      <th>postalCode</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>reviewsCount</th>\n",
       "      <th>totalScore</th>\n",
       "      <th>Type</th>\n",
       "      <th>NOM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tazza di Mattina</td>\n",
       "      <td>5 Rue du Centre Commercial local 5</td>\n",
       "      <td>H8Y 2N9</td>\n",
       "      <td>45.510028</td>\n",
       "      <td>-73.806517</td>\n",
       "      <td>57</td>\n",
       "      <td>4.8</td>\n",
       "      <td>café</td>\n",
       "      <td>Pierrefonds-Roxboro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Loulou Ceramique</td>\n",
       "      <td>15757 Boul. de Pierrefonds</td>\n",
       "      <td>H9H 3X6</td>\n",
       "      <td>45.479232</td>\n",
       "      <td>-73.867688</td>\n",
       "      <td>21</td>\n",
       "      <td>4.8</td>\n",
       "      <td>café</td>\n",
       "      <td>Pierrefonds-Roxboro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Café de Source</td>\n",
       "      <td>4499 Bd des Sources</td>\n",
       "      <td>H8Y 3C1</td>\n",
       "      <td>45.498189</td>\n",
       "      <td>-73.811203</td>\n",
       "      <td>123</td>\n",
       "      <td>4.7</td>\n",
       "      <td>café</td>\n",
       "      <td>Pierrefonds-Roxboro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Café Dépôt Place Vertu</td>\n",
       "      <td>3131 Boul de la Côte-Vertu Place Vertu</td>\n",
       "      <td>H4R 1Y8</td>\n",
       "      <td>45.497253</td>\n",
       "      <td>-73.704253</td>\n",
       "      <td>22</td>\n",
       "      <td>4.0</td>\n",
       "      <td>café</td>\n",
       "      <td>Saint-Laurent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Café Dépôt Ville St-Laurent</td>\n",
       "      <td>2505 Rue des Nations Bombardier, Ville</td>\n",
       "      <td>H4R 3C8</td>\n",
       "      <td>45.513123</td>\n",
       "      <td>-73.711557</td>\n",
       "      <td>376</td>\n",
       "      <td>4.2</td>\n",
       "      <td>café</td>\n",
       "      <td>Saint-Laurent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Burger Fiancé</td>\n",
       "      <td>3627 Sources Blvd</td>\n",
       "      <td>H9B 2K4</td>\n",
       "      <td>45.487953</td>\n",
       "      <td>-73.799888</td>\n",
       "      <td>124</td>\n",
       "      <td>4.9</td>\n",
       "      <td>santé</td>\n",
       "      <td>Dollard-des-Ormeaux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>M Fitness</td>\n",
       "      <td>6900 Bd Décarie #200</td>\n",
       "      <td>H3X 2T8</td>\n",
       "      <td>45.491439</td>\n",
       "      <td>-73.649971</td>\n",
       "      <td>101</td>\n",
       "      <td>3.9</td>\n",
       "      <td>santé</td>\n",
       "      <td>Côte-Saint-Luc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Rachelle-Bery health stores</td>\n",
       "      <td>4810 St Laurent Blvd</td>\n",
       "      <td>H2T 1R5</td>\n",
       "      <td>45.521505</td>\n",
       "      <td>-73.589687</td>\n",
       "      <td>230</td>\n",
       "      <td>4.0</td>\n",
       "      <td>santé</td>\n",
       "      <td>Le Plateau-Mont-Royal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Dagwoods La Sandwicherie</td>\n",
       "      <td>50 Saint-Charles Blvd</td>\n",
       "      <td>H9W 2X3</td>\n",
       "      <td>45.432242</td>\n",
       "      <td>-73.849011</td>\n",
       "      <td>159</td>\n",
       "      <td>4.3</td>\n",
       "      <td>santé</td>\n",
       "      <td>Beaconsfield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>M.T.L. Bagel</td>\n",
       "      <td>5452 Av. Westminster</td>\n",
       "      <td>H4X 2A5</td>\n",
       "      <td>45.458474</td>\n",
       "      <td>-73.660854</td>\n",
       "      <td>411</td>\n",
       "      <td>4.7</td>\n",
       "      <td>santé</td>\n",
       "      <td>Côte-Saint-Luc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2831 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Nom                                     Rue  \\\n",
       "0              Tazza di Mattina      5 Rue du Centre Commercial local 5   \n",
       "1              Loulou Ceramique              15757 Boul. de Pierrefonds   \n",
       "2                Café de Source                     4499 Bd des Sources   \n",
       "3        Café Dépôt Place Vertu  3131 Boul de la Côte-Vertu Place Vertu   \n",
       "4   Café Dépôt Ville St-Laurent  2505 Rue des Nations Bombardier, Ville   \n",
       "..                          ...                                     ...   \n",
       "66                Burger Fiancé                       3627 Sources Blvd   \n",
       "73                    M Fitness                    6900 Bd Décarie #200   \n",
       "74  Rachelle-Bery health stores                    4810 St Laurent Blvd   \n",
       "81     Dagwoods La Sandwicherie                   50 Saint-Charles Blvd   \n",
       "82                 M.T.L. Bagel                    5452 Av. Westminster   \n",
       "\n",
       "   postalCode        Lat        Lon  reviewsCount  totalScore   Type  \\\n",
       "0     H8Y 2N9  45.510028 -73.806517            57         4.8   café   \n",
       "1     H9H 3X6  45.479232 -73.867688            21         4.8   café   \n",
       "2     H8Y 3C1  45.498189 -73.811203           123         4.7   café   \n",
       "3     H4R 1Y8  45.497253 -73.704253            22         4.0   café   \n",
       "4     H4R 3C8  45.513123 -73.711557           376         4.2   café   \n",
       "..        ...        ...        ...           ...         ...    ...   \n",
       "66    H9B 2K4  45.487953 -73.799888           124         4.9  santé   \n",
       "73    H3X 2T8  45.491439 -73.649971           101         3.9  santé   \n",
       "74    H2T 1R5  45.521505 -73.589687           230         4.0  santé   \n",
       "81    H9W 2X3  45.432242 -73.849011           159         4.3  santé   \n",
       "82    H4X 2A5  45.458474 -73.660854           411         4.7  santé   \n",
       "\n",
       "                      NOM  \n",
       "0     Pierrefonds-Roxboro  \n",
       "1     Pierrefonds-Roxboro  \n",
       "2     Pierrefonds-Roxboro  \n",
       "3           Saint-Laurent  \n",
       "4           Saint-Laurent  \n",
       "..                    ...  \n",
       "66    Dollard-des-Ormeaux  \n",
       "73         Côte-Saint-Luc  \n",
       "74  Le Plateau-Mont-Royal  \n",
       "81           Beaconsfield  \n",
       "82         Côte-Saint-Luc  \n",
       "\n",
       "[2831 rows x 9 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_restaurants = pd.concat([Coffee,Greek,Italy,Africain,Antillais,Asian,Mexicain,Healthy])\n",
    "## Drop duplicates si toutes les colonnes sauf la catégogire de l'origine du restaurant est pareille.\n",
    "new_restaurants = new_restaurants.drop_duplicates(subset=[\"Nom\",\"Rue\",\"postalCode\",\"Latitude\",\"Longitude\",\"reviewsCount\",\"totalScore\"])\n",
    "new_restaurants = new_restaurants.rename(columns={'Longitude':'Lon','Latitude':'Lat'})\n",
    "Link_map_data(new_restaurants)\n",
    "nbNew = new_restaurants.groupby(\"NOM\").count()[[\"Nom\"]]\n",
    "nbNew = nbNew.rename(columns={\"Nom\":\"Count of Restaurant\"})\n",
    "new_restaurants = new_restaurants.dropna(subset=[\"NOM\"])\n",
    "new_restaurants = new_restaurants.drop(columns=[\"geometry\"])\n",
    "new_restaurants.to_csv(\"Export/Restaurants.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prop_map = get_location(Propriétés)\n",
    "#Prop_map = get_lat_lon(Prop_map)\n",
    "#Prop_map = Link_map_data(Prop_map)\n",
    "#Prop_map.to_csv('Export/Propriétés_map.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thier\\AppData\\Local\\Temp\\ipykernel_12316\\1881853684.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  price_per_piece[\"price\"] = clean_price\n",
      "C:\\Users\\thier\\AppData\\Local\\Temp\\ipykernel_12316\\1881853684.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  price_per_piece['piece'] = clean_piece\n",
      "C:\\Users\\thier\\AppData\\Local\\Temp\\ipykernel_12316\\1881853684.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  price_per_piece[\"Price_per_piece\"] = (price_per_piece[\"price\"]/price_per_piece[\"piece\"]).astype(int)\n"
     ]
    }
   ],
   "source": [
    "#Prop_map = pd.read_csv(\"CSVs/Propriétés_map.csv\")\n",
    "#tmap = Prop_map.groupby(\"NOM\").count().reset_index()[[\"NOM\",\"car_score\"]]\n",
    "#mapping = pd.merge(Prop_map,tmap, on =\"NOM\", how=\"inner\")\n",
    "#TODO SI t'as une données qui a piece ou nom de propriétés ou prix qui est nulle, on le drop\n",
    "price_per_piece = Prop_map.dropna(subset=[\"piece\",\"NOM\",\"price\"], inplace=False)\n",
    "#TODO 123 456,54$ type String --> 123456 type INT\n",
    "clean_price = [int((re.sub(r'\\u00A0', ' ', r[2])).replace(\" \",\"\").replace(\"$\",\"\")) for i,r in price_per_piece.iterrows()]\n",
    "price_per_piece[\"price\"] = clean_price\n",
    "#TODO retirer pièce du nombre de pièces --> 13 pièces --> 13\n",
    "clean_piece = [int(r[3].replace(\" pièce\",\"\").replace(\"s\",\"\")) for i,r in price_per_piece.iterrows()]\n",
    "price_per_piece['piece'] = clean_piece\n",
    "#TODO Prix/pièce\n",
    "price_per_piece[\"Price_per_piece\"] = (price_per_piece[\"price\"]/price_per_piece[\"piece\"]).astype(int)\n",
    "\n",
    "#price_per_piece = price_per_piece.groupby(\"NOM\").mean(\"Price_per_piece\")[[\"Price_per_piece\"]].astype(int).sort_values(by=\"Price_per_piece\",ascending = False).reset_index()\n",
    "#price_per_piece.to_csv(\"Export/Price_per_piece.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rest_per_km = pd.merge(superficie[[\"NOM\",\"Superficie (km2)\"]],nbNew,on=\"NOM\")\n",
    "#rest_per_km[\"Restaurant_by_km2\"] = (rest_per_km[\"Count of Restaurant\"]/rest_per_km[\"Superficie (km2)\"]).apply(math.ceil)\n",
    "#rest_per_km.to_csv(\"Export/Rest_per_KM.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "975009d07ecb89591f421a82b28366f5e95ebda4302b5da20f317cfbfc51cb08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
